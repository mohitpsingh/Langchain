{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXOn59gbQ4RIyt/KqZNoK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitpsingh/Langchain/blob/feature%2Fchatbot_tutorial/Langchain_Tutorial5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain Runnables"
      ],
      "metadata": {
        "id": "UGpbbyuClhAS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p92ezyplY7Y",
        "outputId": "379eabb4-68b5-46e1-de0a-9268eaeaad01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/109.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "JLW9X2Zql7MG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining Is used where output from the First step is input in 2nd step it is used to break down the task into small pieces."
      ],
      "metadata": {
        "id": "4glGKs3H6Qgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "model = ChatGroq(\n",
        "    model_name=\"mixtral-8x7b-32768\",\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a Joke about {topic}\")\n",
        "\n",
        "chain = prompt | model | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"topic\": \"cat\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uJTCd705mJxY",
        "outputId": "8dcb63a4-82a6-41be-d8d9-46f0d883ab98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, here's a cat joke for you:\\n\\nWhy was the cat sitting on the computer?\\n\\nHe wanted to keep an eye on the mouse!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining can be done with the help of Pipe() or | operator which allow us to pass parameters one after another."
      ],
      "metadata": {
        "id": "dgkOCean6szH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "analysis_prompt = ChatPromptTemplate.from_template(\"is this a funny joke? {joke}\")\n",
        "composed_chain_with_lambda = (\n",
        "    chain\n",
        "    | (lambda input : {\"joke\": input})\n",
        "    | analysis_prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "composed_chain_with_lambda.invoke({\"topic\": \"cat\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "oWAHIoCvsXRJ",
        "outputId": "89f233bf-9b7e-40d2-d583-fe7666313727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'m just an AI language model, so I don\\'t experience humor the way humans do. However, I can tell you that this is a classic joke format, where the punchline plays on a word that sounds similar to another word with a different meaning. In this case, the joke is that cheetahs, which sound like \"cheaters,\" are present in the jungle, making it an unfavorable environment for cats to play poker due to the presence of cheaters.\\n\\nWhile I don\\'t find jokes funny myself, I can understand how the structure and wordplay might amuse some people. If you found this joke entertaining, then I\\'m glad I could share something enjoyable with you! If you have any other questions or need assistance, feel free to ask.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}