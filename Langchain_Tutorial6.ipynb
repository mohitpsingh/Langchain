{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuoI9rfVAnKNO2fXXdp9e/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitpsingh/Langchain/blob/feature%2Fchatbot_tutorial/Langchain_Tutorial6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to pass tool outputs to chat models"
      ],
      "metadata": {
        "id": "crjvzq6kGhm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpwzIVZ0Gewi",
        "outputId": "7b23a047-0ff4-48ca-a042-a139a317f3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "Dz-uRsyjGwbO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model = \"llama3-8b-8192\",\n",
        "    temperature = 0\n",
        ")\n"
      ],
      "metadata": {
        "id": "ylCRUkubG_Sb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds a and b.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiplies a and b.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "tools = [add, multiply]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "eOXdAXE0Hc1V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
        "\n",
        "messages = [HumanMessage(query)]\n",
        "\n",
        "ai_msg = llm_with_tools.invoke(messages)\n",
        "\n",
        "print(ai_msg.tool_calls)\n",
        "\n",
        "messages.append(ai_msg)\n",
        "print(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udq9ZzPQIZCd",
        "outputId": "d50588d7-bad5-4667-f940-133070504349"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_brp6', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_rysy', 'type': 'tool_call'}]\n",
            "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_brp6', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_rysy', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 1045, 'total_tokens': 1184, 'completion_time': 0.115833333, 'prompt_time': 0.124360372, 'queue_time': 0.020309266999999992, 'total_time': 0.240193705}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b027efe0-8b4b-4ce0-ac25-1188f1ef868f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_brp6', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_rysy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1045, 'output_tokens': 139, 'total_tokens': 1184})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tool_call in ai_msg.tool_calls:\n",
        "  selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
        "  tool_msg = selected_tool.invoke(tool_call)\n",
        "  messages.append(tool_msg)\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ4MAGgyMxvG",
        "outputId": "e4bcafc2-f3b7-4353-f43d-f48494ca9797"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1fqs', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_0mrj', 'function': {'arguments': '{\"a\":11,\"b\":49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 1045, 'total_tokens': 1184, 'completion_time': 0.115833333, 'prompt_time': 0.124666014, 'queue_time': 0.019263044999999993, 'total_time': 0.240499347}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d0d1ec9c-1adb-49f8-b182-f6fd4b0451d5-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_1fqs', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_0mrj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1045, 'output_tokens': 139, 'total_tokens': 1184}),\n",
              " ToolMessage(content='36', name='multiply', tool_call_id='call_1fqs'),\n",
              " ToolMessage(content='60', name='add', tool_call_id='call_0mrj')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}